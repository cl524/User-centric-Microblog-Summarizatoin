{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d9cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, string, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18575701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('../triple_long_sf_Vax.csv', header=0, encoding='ISO-8859-1', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcea7491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13806"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75db44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.drop_duplicates(subset=['triple_string'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d1c2610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13806"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7e2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1[(df1['sentiment']==0) | (df1['sentiment']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b026b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5423"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20e29b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56511b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\cl524\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import contractions\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "########################################################################################\n",
    "def normalize_document(doc):\n",
    "    #nns=[\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    doc = contractions.fix(doc)\n",
    "\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "\n",
    "    filtered_tokenss = [token for token in tokens if (token not in stop_words) and (len(token)>2)]\n",
    "    filtered_tokenss = [lemmatizer.lemmatize(token, pos =\"n\") for token in filtered_tokenss ]\n",
    "\n",
    "    ######################################################################\n",
    "    doc = ' '.join(filtered_tokenss)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fca67b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "926\n",
      "926\n",
      "['vaccine', 'efficacy', 'vaccine', 'mike penny', 'covid vaccine', '', 'presidentelect joebiden', 'good news', 'good news', 'mrna vaccine']\n",
      "926\n"
     ]
    }
   ],
   "source": [
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "norm_corpus = normalize_corpus(list(df1['subject']))\n",
    "print(len(norm_corpus))\n",
    "tokenized_docs = [(doc.split())[-2:] for doc in norm_corpus]\n",
    "\n",
    "processedSub=[]\n",
    "\n",
    "print(len(tokenized_docs))\n",
    "for t in tokenized_docs:\n",
    "    processedSub.append(\" \".join(t))\n",
    "    \n",
    "print(processedSub[:10])\n",
    "print(len(processedSub))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e119005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753\n"
     ]
    }
   ],
   "source": [
    "df1['processedSub']=processedSub\n",
    "\n",
    "df1=df1[df1['processedSub']!='']\n",
    "\n",
    "print(len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4f8fab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "dout=DataFrame()\n",
    "\n",
    "\n",
    "dout=df1\n",
    "\n",
    "dout=dout#.sort_values(by = ['dateTime'], ascending = [True])\n",
    "print(len(dout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16895754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df243c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a1060d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "salience=[]\n",
    "\n",
    "for f, r in zip(list(df1['followers']), list(df1['retweets'])):\n",
    "    if f>0 and r>0:\n",
    "        salience.append(int(f)+int(r)*707)\n",
    "    elif r==0:\n",
    "        salience.append(int(f))\n",
    "    else:\n",
    "        salience.append(0)\n",
    "\n",
    "df1['salienceScore']=salience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2f8cd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15      240308\n",
      "71       15399\n",
      "84     7993639\n",
      "85       15378\n",
      "110     811811\n",
      "Name: salienceScore, dtype: int64 15      240308\n",
      "71       15399\n",
      "84     7991518\n",
      "85       15378\n",
      "110     809690\n",
      "Name: followers, dtype: int64 15     0\n",
      "71     0\n",
      "84     3\n",
      "85     0\n",
      "110    3\n",
      "Name: retweets, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1['salienceScore'][:5], df1['followers'][:5], df1['retweets'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a5239a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dout=DataFrame()\n",
    "dout=df1.sort_values([\"salienceScore\"], ascending=[False]).head(18)\n",
    "dout=dout.sort_values(by=['postInd', 'sentenceInd', 'tripleInd'], ascending=[True, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7bc2af11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "dout2=dout#.drop_duplicates(subset=['postInd', 'sentenceInd'], keep='first')\n",
    "print(len(dout2))\n",
    "\n",
    "from pandas import DataFrame\n",
    "dout_sent=DataFrame()#(columns=['dateTime', 'postInd', 'sentenceInd', 'tripleInd', 'subject', 'relation', 'object', 'sentence', 'userId', 'followers', 'retweets', 'salienceScore', 'vacccines'])\n",
    "\n",
    "dout_sent['dateTime'] = list(dout2['dateTime'])\n",
    "dout_sent['postInd'] = list(dout2['postInd'])\n",
    "dout_sent['sentenceInd'] = list(dout2['sentenceInd'])\n",
    "dout_sent['tripleInd'] = list(dout2['tripleInd'])\n",
    "dout_sent['subject'] = list(dout2['processedSub'])\n",
    "dout_sent['relation'] = list(dout2['relation'])\n",
    "dout_sent['object'] = list(dout2['object'])\n",
    "dout_sent['sentiment'] = list(dout2['sentiment'])\n",
    "dout_sent['country'] = list(dout2['country'])\n",
    "dout_sent['sentence'] = list(dout2['sentence'])\n",
    "dout_sent['post'] = list(dout2['post'])\n",
    "dout_sent['userId'] = list(dout2['userId'])\n",
    "dout_sent['followers'] = list(dout2['followers'])\n",
    "dout_sent['retweets'] = list(dout2['retweets'])\n",
    "dout_sent['salienceScore'] = list(dout2['salienceScore'])\n",
    "dout_sent['vaccines'] = list(dout2['vaccines'])\n",
    "\n",
    "dout_sent['tripleS']=dout_sent['subject']+\" \"+dout_sent['relation']+\" \"+dout_sent['object']\n",
    "\n",
    "dout_sent.to_csv('tripleSent_summary_world_POS.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af456a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(list(set(list(dout_sent['userId'])))))\n",
    "print(len(list(set(list(dout_sent['sentence'])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29646af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>followers</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vaccines</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>covaxin</th>\n",
       "      <td>30</td>\n",
       "      <td>118705315</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderna pfizer</th>\n",
       "      <td>3</td>\n",
       "      <td>13115701</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinopharm</th>\n",
       "      <td>6</td>\n",
       "      <td>26231740</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinovac</th>\n",
       "      <td>12</td>\n",
       "      <td>52463504</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sputnik</th>\n",
       "      <td>3</td>\n",
       "      <td>1015996</td>\n",
       "      <td>12925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sentiment  followers  retweets\n",
       "vaccines                                      \n",
       "covaxin                30  118705315       619\n",
       "moderna pfizer          3   13115701        10\n",
       "sinopharm               6   26231740       212\n",
       "sinovac                12   52463504        17\n",
       "sputnik                 3    1015996     12925"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dout_sent.groupby(['vaccines']).sum(['retweets'])).drop(['userId', 'postInd', 'sentenceInd', 'tripleInd', 'salienceScore'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "efd2e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e6e77f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dk=pd.read_csv(\"tripleSent_summary_world_POS.csv\", header=0, encoding='ISO-8859-1', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae5385d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "baf49441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "['The 80-year-old three-time World Cup champion called it an unforgettable day and urged discipline to preserve lives.', 'The COVID-19 vaccine developed by Chinas Sinopharm has been approved for emergency use in the Maldives, the Maldives Food and Drug Administration announced at a press conference Monday afternoon.', 'Azerbaijan on Thursday received a batch of Sinovacs COVID-19 vaccines that it directly purchased from China.', 'Serbian President Aleksandar Vucic avucic received a dose of Chinese Sinopharm COVID-19 vaccine on Tuesday, encouraging more people to join the immunization, according to local media.', 'Delhi high court refuses to stay Covaxin trial among children (RichaBanka reports)', 'I request for your kind intervention so that an early approval is received for Covaxin from WHO', 'The U.S. drug regulator on Friday added a warning to the literature that accompanies Moderna and Pfizer-BioNTech COVID-19 vaccine shots, indicating the rare risk of heart inflammation after its use.', 'Accept Covishield, Covaxin Or Face Mandatory Quarantine, India Tells EU', 'The Union health ministry cited a large-scale, real-life study conducted by the ICMR and said that two doses of Covidvaccines, irrespective of Covishield and Covaxin, were successful to extend 95% protection from death.', 'Covaxin receives certificate of Good Manufacturing Practice from Hungarian authorities.', 'ICMR study Watch for details', 'We want to ensure equitable access of the vaccine to every Indian citizen, and the expansion of Covaxin production facilities by Bharat Biotech will take us closer to this goal.', 'Dr Sumit Ray, Holy Family Hospital, on delay in Covaxin approval by the World Health Organisation.', 'Bharat Biotechs Covaxin, the vaccine against Covid19, has received the recommendation of a SEC for use in children between the ages 2 to 18', 'PM NarendraModi jis visionary decision to back our scientists & researchers is now a perfect Diwali Gift from to the World.', 'This video fits the last almost 2 years into 2 minutes.']\n",
      "305\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "dout=DataFrame()\n",
    "\n",
    "\n",
    "dk=dk.drop_duplicates(subset=['postInd', 'sentenceInd'], keep='first')\n",
    "print(len(dk))\n",
    "\n",
    "sentences=list(dk['sentence'])\n",
    "summary_sent=[]\n",
    "for p in sentences:\n",
    "    p=str(p)\n",
    "    p=re.sub(r'(\\n)(\\s+)', r'\\1', p)\n",
    "    p=re.sub(r'(\\s+)(\\n)', r'\\2', p)\n",
    "    p=re.sub(r'(\\n)', r' ', p)\n",
    "    \n",
    "    z=0\n",
    "    while( z<len(p) and (p[z].isalpha()!=True and p[z].isnumeric()!=True) ):\n",
    "        z+=1\n",
    "    \n",
    "    p=p[z:]\n",
    "    p=p.strip()\n",
    "    p=re.sub(\" +\", \" \", p)\n",
    "\n",
    "    summary_sent.append(p)\n",
    "\n",
    "\n",
    "\n",
    "leng=[]\n",
    "print(summary_sent)\n",
    "print(len((\" \".join(sentences)).split(\" \")))\n",
    "leng.append(len((\" \".join(sentences)).split(\" \")))\n",
    "\n",
    "finalS=[]\n",
    "finalS.append(\" \".join(summary_sent))\n",
    "\n",
    "df_out_sentence=DataFrame(zip(finalS, leng), columns=['summary', 'leng'])\n",
    "df_out_sentence.to_csv(\"summarySent_world_POS.csv\", header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32134de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ab5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63663614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
